#!/usr/bin/env python

from pispino.seqprep import *

__author__     = "Hyun Soon Gweon"
__copyright__  = "Copyright 2015, Originally from the PIPITS Project"
__credits__    = ["Hyun Soon Gweon", "Anna Oliver", "Joanne Taylor", "Tim Booth", "Melanie Gibbs", "Daniel S. Read", "Robert I. Griffiths", "Karsten Schonrogge"]
__license__    = "GPL"
__maintainer__ = "Hyun Soon Gweon"
__email__      = "h.s.gweon@reading.ac.uk"

if __name__ == '__main__':

    parser = argparse.ArgumentParser(description = "pispino_seqprep: reindex, join, quality filter, convert and merge!")
    parser.add_argument(
        "-i",
        action = "store",
        dest = "dataDir",
        metavar = "<DIR>",
        help = "[REQUIRED] Directory with raw sequences in gzipped FASTQ",
        required = True)
    parser.add_argument(
        "-o",
        action = "store",
        dest = "outputdir",
        metavar = "<DIR>",
        help = "[REQUIRED] Directory to output results",
        default = "pispino_seqprep_output",
        required = False)
    parser.add_argument(
        "-l",
        action = "store",
        dest = "listfile",
        metavar = "<FILE>",
        help = "Tap separated file with three columns for sample ids, forward-read filename and reverse-read filename. Only the files listed in this file will be processed.",
        required = False)
    parser.add_argument(
        "--FASTX-q",
        action = "store",
        dest = "FASTX_fastq_quality_filter_q",
        metavar = "<INT>",
        help = "FASTX FASTQ_QUALITY_FILTER - Minimum quality score to keep [default: 30]",
        default = "30",
        required = False)
    parser.add_argument(
        "--FASTX-p",
        action = "store",
        dest = "FASTX_fastq_quality_filter_p",
        metavar = "<INT>",
        help = "FASTX FASTQ_QUALITY_FILTER - Minimum percent of bases that must have q quality [default: 80]",
        default = "80",
        required = False)
    parser.add_argument(
        "--FASTX-n",
        action = "store_true",
        dest = "FASTX_fastq_to_fasta_n",
        help = "FASTX FASTQ_TO_FASTA - remove sequences with unknown (N) nucleotides [default: false]",
        required = False)
    parser.add_argument(
        "-b",
        action = "store",
        dest = "base_phred_quality_score",
        metavar = "<INT>",
        help = "Base PHRED quality score [default: 33]",
        default = "33",
        required = False)
    parser.add_argument(
        "--joiner_method",
        action = "store",
        dest = "joiner_method",
        help = "Joiner method: \"PEAR\" and \"FASTQJOIN\" [default: VSEARCH]",
        required = False,
        default = "VSEARCH",
        choices = ["VSEARCH", "PEAR", "FASTQJOIN"])
    parser.add_argument(
        "--PEAR_options=",
        type = str,
        metavar = "<STR>",
        action = "store",
        dest = "PEAR_options",
        help = "User customisable parameter: You can add/change PEAR parameters. Please use \"--PEAR_options=\" followed by custom parameters wrapped around them. E.g. --PEAR_options=\"-v 8 -t 2\". Note that if you put two same parameters such as \"-v 8 -v 15\", PEAR will use the later.",
        required = False,
        default = "")
    parser.add_argument(
        "-r",
        action = "store_true",
        dest = "retain",
        help = "Retain intermediate files (Beware intermediate files use excessive disk space!)",
        required = False)
    parser.add_argument(
        "-v",
        action = "store_true",
        dest = "verbose",
        help = "Verbose mode",
        required = False)
    parser.add_argument(
        "-t",
        action = "store",
        dest = "threads",
        metavar = "<INT>",
        help = "Number of Threads [default: 1]",
        default = "1",
        required = False)
    parser.add_argument(
        "--forwardreadsonly",
        action = "store_true",
        dest = "forwardreadsonly",
        help = "Do NOT join paired-end sequences, but just use the forward reads.",
        required = False)
    options = parser.parse_args()

    
    # Make directories (outputdir and tmpdir)
    if not os.path.exists(options.outputdir):
        os.mkdir(options.outputdir)

    tmpDir = options.outputdir + "/tmp"
    if not os.path.exists(tmpDir):
        os.mkdir(tmpDir)

    # Log files                                                                                                                                                                                                                              
    logging_file = open(options.outputdir + "/output.log", "w")
    summary_file = open(options.outputdir + "/summary.log", "w")

    # Start!
    logger_info(BLUE + "pispino_seqprep started" + ENDC, logging_file)


    # Check for the presence of rawdata directory
    logger_verbose("Checking for presence of input directory", logging_file, options.verbose)
    if not os.path.exists(options.dataDir):
        logger_error("Cannot find \"" + options.dataDir + "\" directory. Ensure you have the correct name of the directory where your Illumina sequences are stored", logging_file)
        exit(1)

    sampleids = []
    fastqs_f = []
    fastqs_r = []


    # Load sampleids and filenames
    if options.listfile:
        logger_info(HEADER + "Checking listfile" + ENDC, logging_file)
        try:
            listfile = open(options.listfile, "r")
        except IOError:
            logger_error("\"" + options.listfile + "\" not found.", logging_file)
            exit(1)
        for line in listfile:
            if line.strip(" ").strip("\n") != "" and not line.startswith("#"):
                line_split = line.rstrip().split("\t")

                if line_split[0].find("_") != -1:
                    logger_error("\"_\" is not allowed in the sample id", logging_file)
                    exit(1)

                sampleids.append(line_split[0])
                fastqs_f.append(line_split[1])
                fastqs_r.append(line_split[2])
        listfile.close()
        logger_info(GREEN + "... done" + ENDC, logging_file)

    else:
        logger_error("Please run pipits_getreadpairslist or pipits_getreadsingleslist to generate a list file", logging_file)
        exit(1)

    # Check if both files have the same number of sequences
    if len(fastqs_f) != len(fastqs_r):
        logger_error("Different number of forward FASTQs and reverse FASTQs", logging_file)
        exit(1)

    # Count
    logger_info(HEADER + "Counting sequences in rawdata" + ENDC, logging_file)
    count_sequences(input_dir = options.dataDir,
                    filenames_list = fastqs_f,
                    logging_file = logging_file,
                    summary_file = summary_file,
                    verbose = options.verbose)

    # Re-index forward reads
    logger_info(HEADER + "Reindexing forward reads" + ENDC, logging_file)
    reindex_fastq(input_dir = options.dataDir,
                  output_dir = options.outputdir + "/tmp/reindex_fastq_F",
                  sampleids_list = sampleids,
                  filenames_list = fastqs_f,
                  logging_file = logging_file,
                  summary_file = summary_file,
                  verbose = options.verbose)
    logger_info(GREEN + "... done" + ENDC, logging_file)

    # Re-index reverse reads
    logger_info(HEADER + "Reindexing reverse reads" + ENDC, logging_file)
    reindex_fastq(input_dir = options.dataDir,
                  output_dir = options.outputdir + "/tmp/reindex_fastq_R",
                  sampleids_list = sampleids,
                  filenames_list = fastqs_r,
                  logging_file = logging_file,
                  summary_file = summary_file,
                  verbose = options.verbose)
    logger_info(GREEN + "... done" + ENDC, logging_file)

    # Join
    if options.forwardreadsonly:
        justForwardReads(input_dir_f = options.outputdir + "/tmp/reindex_fastq_F",
                         input_dir_r = options.outputdir + "/tmp/reindex_fastq_R",
                         output_dir = options.outputdir + "/tmp/joined",
                         sampleids_list = sampleids,
                         base_phred_quality_score = options.base_phred_quality_score,
                         joiner_method = options.joiner_method,
                         threads = options.threads,
                         PEAR_parameters = options.PEAR_options,
                         logging_file = logging_file,
                         summary_file = summary_file,
                         verbose = options.verbose)
    else:
        join(input_dir_f = options.outputdir + "/tmp/reindex_fastq_F",
             input_dir_r = options.outputdir + "/tmp/reindex_fastq_R",
             output_dir = options.outputdir + "/tmp/joined",
             sampleids_list = sampleids,
             base_phred_quality_score = options.base_phred_quality_score,
             joiner_method = options.joiner_method,
             threads = options.threads,
             PEAR_parameters = options.PEAR_options,
             logging_file = logging_file,
             summary_file = summary_file,
             verbose = options.verbose)

    # Quality filter
    qualityfilter(input_dir = options.outputdir + "/tmp/joined",
                  output_dir = options.outputdir + "/tmp/qualityfiltered",
                  sampleids_list = sampleids,
                  base_phred_quality_score = options.base_phred_quality_score,
                  FASTX_fastq_quality_filter_q = options.FASTX_fastq_quality_filter_q,
                  FASTX_fastq_quality_filter_p = options.FASTX_fastq_quality_filter_p,
                  logging_file = logging_file,
                  summary_file = summary_file,
                  verbose = options.verbose)

    # Convert
    convert(input_dir = options.outputdir + "/tmp/qualityfiltered",
            output_dir = options.outputdir + "/tmp/fastqtofasta",
            sampleids_list = sampleids,
            base_phred_quality_score = options.base_phred_quality_score,
            FASTX_fastq_to_fasta_n = options.FASTX_fastq_to_fasta_n,
            logging_file = logging_file,
            summary_file = summary_file,
            verbose = options.verbose)
    
    # Merge
    merge(input_dir = options.outputdir + "/tmp/fastqtofasta",
          output_dir = options.outputdir,
          sampleids_list = sampleids,
          logging_file = logging_file,
          verbose = options.verbose)

    # Clean up tmp_directory
    if not options.retain:
        logger_info(HEADER + "Cleaning temporary directory" + ENDC, logging_file)
        shutil.rmtree(options.outputdir + "/tmp")
        logger_info(GREEN + "... done" + ENDC, logging_file)

    # Done
    logger_info(GREEN + "Done" + ENDC + " - pispino_seqprep completed (Resulting file: " + options.outputdir + "/prepped.fasta)" + ENDC, logging_file)

    logging_file.close()
    summary_file.close()

    exit(0)
